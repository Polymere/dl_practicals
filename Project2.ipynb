{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Mini deep-learning framework\n",
    "\n",
    "https://fleuret.org/ee559/ee559-miniprojects.pdf\n",
    "    \n",
    "https://www.overleaf.com/8773141819qyxryzqggdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor,set_grad_enabled,empty,float32,ones\n",
    "set_grad_enabled(False);\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=tensor([-1,1])\n",
    "t.rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLayer:\n",
    "    def __init__(self,activation,shape,bias):\n",
    "        self.weights=self._init_weights(shape)\n",
    "        self.bias=self._init_bias(bias,shape[0])\n",
    "        self._thr_func=activation\n",
    "        \n",
    "    def bckwrd(self,prev_delta,prev_act):\n",
    "        resp=(self.weights*prev_delta+self.bias.view(-1)).sum(1)\n",
    "        return self._der_thr(prev_act)*resp\n",
    "\n",
    "    def frwrd(self,prev_input):\n",
    "        return self._thr((self.weights*prev_input+self.bias.view(-1)).sum(1))\n",
    "    \n",
    "    def updt_weights(self,err,act,gamma):\n",
    "        print(self.weights)\n",
    "        self.weights=self.weights-gamma*err*act\n",
    "        print(self.weights)\n",
    "    def _init_weights(self,sz):\n",
    "        return ones((sz[0],sz[1]),dtype=float32)\n",
    "    def _init_bias(self,bias_val,sz):\n",
    "        return bias_val*ones((sz,1),dtype=float32)\n",
    "    def _thr(self,tens):\n",
    "        if self._thr_func==\"relu\":\n",
    "            return tens*(tens>0).float()\n",
    "        elif self._thr_func==\"tanh\":\n",
    "            return tens.tanh()\n",
    "    def _der_thr(self,tens):\n",
    "        if self._thr_func==\"relu\":\n",
    "            return 1*(tens>0).float()\n",
    "        elif self._thr_func==\"tanh\":\n",
    "            return 1-(tens.tanh())^2\n",
    "\n",
    "class myNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers=[]\n",
    "        self.weights=[]\n",
    "        self.lr=0.001\n",
    "    def add_layer(self,activation,shape,bias_val):\n",
    "        self.layers.append(myLayer(activation,shape,bias_val))\n",
    "        \n",
    "    def weights_as_image(self):\n",
    "        for lay in self.layers:\n",
    "            plt.imshow(lay.weights)\n",
    "    def weights_values(self):\n",
    "        print(\"\\n**************\")\n",
    "        for lay in self.layers:\n",
    "            print(lay.weights)\n",
    "            \n",
    "    def forward(self,x):\n",
    "        prev_input=x\n",
    "        activities=[]\n",
    "        for lay in self.layers:\n",
    "            prev_input=lay.frwrd(prev_input)\n",
    "            activities.append(prev_input)\n",
    "        return activities\n",
    "    def err(self,y,yhat,kind=\"rms\"):\n",
    "        if kind==\"rms\":\n",
    "            return (y**2-yhat**2).sum()\n",
    "    def backward(self,err,activities):\n",
    "        delta_lay=err\n",
    "        for lay,act in zip(reversed(self.layers),reversed(activities)):\n",
    "            lay.updt_weights(delta_lay,act,self.lr)\n",
    "            delta_lay=lay.bckwrd(delta_lay,act)\n",
    "        return delta_lay\n",
    "    \n",
    "\n",
    "\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.5280, 1.5280, 1.5280],\n",
      "        [1.5280, 1.5280, 1.5280],\n",
      "        [1.5280, 1.5280, 1.5280]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.8068, 1.8068, 1.8068],\n",
      "        [1.8068, 1.8068, 1.8068],\n",
      "        [1.8068, 1.8068, 1.8068]])\n",
      "-803.15771484375\n",
      "tensor([[1.5280, 1.5280, 1.5280],\n",
      "        [1.5280, 1.5280, 1.5280],\n",
      "        [1.5280, 1.5280, 1.5280]])\n",
      "tensor([[14.8320, 14.8320, 14.8320],\n",
      "        [14.8320, 14.8320, 14.8320],\n",
      "        [14.8320, 14.8320, 14.8320]])\n",
      "tensor([[1.8068, 1.8068, 1.8068],\n",
      "        [1.8068, 1.8068, 1.8068],\n",
      "        [1.8068, 1.8068, 1.8068]])\n",
      "tensor([[130.9459, 130.9459, 130.9459],\n",
      "        [130.9459, 130.9459, 130.9459],\n",
      "        [130.9459, 130.9459, 130.9459]])\n",
      "-407385792.0\n",
      "tensor([[14.8320, 14.8320, 14.8320],\n",
      "        [14.8320, 14.8320, 14.8320],\n",
      "        [14.8320, 14.8320, 14.8320]])\n",
      "tensor([[4.7473e+09, 4.7473e+09, 4.7473e+09],\n",
      "        [4.7473e+09, 4.7473e+09, 4.7473e+09],\n",
      "        [4.7473e+09, 4.7473e+09, 4.7473e+09]])\n",
      "tensor([[130.9459, 130.9459, 130.9459],\n",
      "        [130.9459, 130.9459, 130.9459],\n",
      "        [130.9459, 130.9459, 130.9459]])\n",
      "tensor([[1.5195e+18, 1.5195e+18, 1.5195e+18],\n",
      "        [1.5195e+18, 1.5195e+18, 1.5195e+18],\n",
      "        [1.5195e+18, 1.5195e+18, 1.5195e+18]])\n",
      "-inf\n",
      "tensor([[4.7473e+09, 4.7473e+09, 4.7473e+09],\n",
      "        [4.7473e+09, 4.7473e+09, 4.7473e+09],\n",
      "        [4.7473e+09, 4.7473e+09, 4.7473e+09]])\n",
      "tensor([[inf, inf, inf],\n",
      "        [inf, inf, inf],\n",
      "        [inf, inf, inf]])\n",
      "tensor([[1.5195e+18, 1.5195e+18, 1.5195e+18],\n",
      "        [1.5195e+18, 1.5195e+18, 1.5195e+18],\n",
      "        [1.5195e+18, 1.5195e+18, 1.5195e+18]])\n",
      "tensor([[inf, inf, inf],\n",
      "        [inf, inf, inf],\n",
      "        [inf, inf, inf]])\n",
      "nan\n",
      "tensor([[inf, inf, inf],\n",
      "        [inf, inf, inf],\n",
      "        [inf, inf, inf]])\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "tensor([[inf, inf, inf],\n",
      "        [inf, inf, inf],\n",
      "        [inf, inf, inf]])\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "nan\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "\n",
      "**************\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n",
      "tensor([[nan, nan, nan],\n",
      "        [nan, nan, nan],\n",
      "        [nan, nan, nan]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/python/miniconda3/envs/dl/lib/python3.7/site-packages/matplotlib/image.py:395: UserWarning: Warning: converting a masked element to nan.\n",
      "  dv = (np.float64(self.norm.vmax) -\n",
      "/home/paul/python/miniconda3/envs/dl/lib/python3.7/site-packages/matplotlib/image.py:396: UserWarning: Warning: converting a masked element to nan.\n",
      "  np.float64(self.norm.vmin))\n",
      "/home/paul/python/miniconda3/envs/dl/lib/python3.7/site-packages/matplotlib/image.py:403: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_min = np.float64(newmin)\n",
      "/home/paul/python/miniconda3/envs/dl/lib/python3.7/site-packages/matplotlib/image.py:408: UserWarning: Warning: converting a masked element to nan.\n",
      "  a_max = np.float64(newmax)\n",
      "/home/paul/python/miniconda3/envs/dl/lib/python3.7/site-packages/matplotlib/colors.py:918: UserWarning: Warning: converting a masked element to nan.\n",
      "  dtype = np.min_scalar_type(value)\n",
      "/home/paul/python/miniconda3/envs/dl/lib/python3.7/site-packages/numpy/ma/core.py:718: UserWarning: Warning: converting a masked element to nan.\n",
      "  data = np.array(a, copy=False, subok=subok)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nw=myNetwork()\n",
    "nw.add_layer('relu',(3,3),0)\n",
    "nw.add_layer('relu',(3,3),0)\n",
    "\n",
    "x=tensor([1,2,-1],dtype=float32)\n",
    "y=tensor([2,4,0],dtype=float32)\n",
    "act=nw.forward(x)\n",
    "err=nw.err(y,act[-1])\n",
    "nw.backward(err,act)\n",
    "err_lst=[]\n",
    "for i in range(5):\n",
    "    act=nw.forward(x)\n",
    "    err=nw.err(y,act[-1])\n",
    "    print(err.item())\n",
    "    err_lst.append(err.item())\n",
    "    nw.backward(err,act)\n",
    "nw.weights_as_image()\n",
    "#plt.plot(err_lst)\n",
    "nw.weights_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-483549fc531e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "test=myNetwork()\n",
    "test.add_layer('tanh',(2,25),1)\n",
    "test.add_layer('tanh',(25,25),1)\n",
    "test.add_layer('tanh',(25,25),1)\n",
    "test.add_layer('tanh',(25,25),1)\n",
    "test.add_layer('relu',(25,2),1)\n",
    "x=tensor([1,2],dtype=float32)\n",
    "y=tensor([1,5],dtype=float32)\n",
    "test.forward(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
